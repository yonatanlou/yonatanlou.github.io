<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0"> 
        <link rel="icon" href="/favicon.ico">
        <title>Yonatan Lourie</title>
        <meta name="description" content="In case you got curious and want to do some cool stuff with one of the ancient texts ever found.">
        <link rel="alternate" href="feed/feed.xml" type="application/atom+xml" title="Yonatan Lourie">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
        
        <script async="" src="https://www.googletagmanager.com/gtag/js?id=G-C6PG57BBFC"></script>
        <script>
            window.dataLayer = window.dataLayer || [];
            function gtag() {
                dataLayer.push(arguments);
            }
            gtag('js', new Date());
            gtag('config', 'G-C6PG57BBFC');
        </script>
        
        <style>
        /**
 * okaidia theme for JavaScript, CSS and HTML
 * Loosely based on Monokai textmate theme by http://www.monokai.nl/
 * @author ocodia
 */

code[class*="language-"],
pre[class*="language-"] {
	color: #f8f8f2;
	background: none;
	text-shadow: 0 1px rgba(0, 0, 0, 0.3);
	font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
	font-size: 1em;
	text-align: left;
	white-space: pre;
	word-spacing: normal;
	word-break: normal;
	word-wrap: normal;
	line-height: 1.5;

	-moz-tab-size: 4;
	-o-tab-size: 4;
	tab-size: 4;

	-webkit-hyphens: none;
	-moz-hyphens: none;
	-ms-hyphens: none;
	hyphens: none;
}

/* Code blocks */
pre[class*="language-"] {
	padding: 1em;
	margin: .5em 0;
	overflow: auto;
	border-radius: 0.3em;
}

:not(pre) > code[class*="language-"],
pre[class*="language-"] {
	background: #272822;
}

/* Inline code */
:not(pre) > code[class*="language-"] {
	padding: .1em;
	border-radius: .3em;
	white-space: normal;
}

.token.comment,
.token.prolog,
.token.doctype,
.token.cdata {
	color: #8292a2;
}

.token.punctuation {
	color: #f8f8f2;
}

.token.namespace {
	opacity: .7;
}

.token.property,
.token.tag,
.token.constant,
.token.symbol,
.token.deleted {
	color: #f92672;
}

.token.boolean,
.token.number {
	color: #ae81ff;
}

.token.selector,
.token.attr-name,
.token.string,
.token.char,
.token.builtin,
.token.inserted {
	color: #a6e22e;
}

.token.operator,
.token.entity,
.token.url,
.language-css .token.string,
.style .token.string,
.token.variable {
	color: #f8f8f2;
}

.token.atrule,
.token.attr-value,
.token.function,
.token.class-name {
	color: #e6db74;
}

.token.keyword {
	color: #66d9ef;
}

.token.regex,
.token.important {
	color: #fd971f;
}

.token.important,
.token.bold {
	font-weight: bold;
}
.token.italic {
	font-style: italic;
}

.token.entity {
	cursor: help;
}
/*
 * New diff- syntax
 */

pre[class*="language-diff-"] {
	--eleventy-code-padding: 1.25em;
	padding-left: var(--eleventy-code-padding);
	padding-right: var(--eleventy-code-padding);
}
.token.deleted {
	background-color: hsl(0, 51%, 37%);
	color: inherit;
}
.token.inserted {
	background-color: hsl(126, 31%, 39%);
	color: inherit;
}

/* Make the + and - characters unselectable for copy/paste */
.token.prefix.unchanged,
.token.prefix.inserted,
.token.prefix.deleted {
	-webkit-user-select: none;
	user-select: none;
	display: inline-flex;
	align-items: center;
	justify-content: center;
	padding-top: 2px;
	padding-bottom: 2px;
}
.token.prefix.inserted,
.token.prefix.deleted {
	width: var(--eleventy-code-padding);
	background-color: rgba(0,0,0,.2);
}

/* Optional: full-width background color */
.token.inserted:not(.prefix),
.token.deleted:not(.prefix) {
	display: block;
	margin-left: calc(-1 * var(--eleventy-code-padding));
	margin-right: calc(-1 * var(--eleventy-code-padding));
	text-decoration: none; /* override del, ins, mark defaults */
	color: inherit; /* override del, ins, mark defaults */
}
/* This is an arbitrary CSS string added to the bundle */
/* Defaults */
:root {
	--font-family: -apple-system, system-ui, sans-serif;
	--font-family-monospace: Consolas, Menlo, Monaco, Andale Mono WT, Andale Mono, Lucida Console, Lucida Sans Typewriter, DejaVu Sans Mono, Bitstream Vera Sans Mono, Liberation Mono, Nimbus Mono L, Courier New, Courier, monospace;
}

/* Theme colors */
:root {
	--color-gray-20: #e0e0e0;
	--color-gray-50: #C0C0C0;
	--color-gray-90: #333;
	/* Change to a darker shade */

	--background-color: #f5f5f5;
	/* Lighter background */

	--text-color: #333;
	/* Change to a darker shade */
	--text-color-link: #007bff;
	--text-color-link-active: #0056b3;
	--text-color-link-visited: #563d7c;
}

/* @media (prefers-color-scheme: light) {
	:root {
		--color-gray-20: #e0e0e0;
		--color-gray-50: #C0C0C0;
		--color-gray-90: #dad8d8;

		--text-color-link: #1493fb;
		--text-color-link-active: #6969f7;
		--text-color-link-visited: #a6a6f8;

		--background-color: #79bcff;
	}
} */


/* Global stylesheet */
* {
	box-sizing: border-box;
}

@view-transition {
	navigation: auto;
}

html,
body {
	padding: 0;
	margin: 0 auto;
	font-family: var(--font-family);
	color: var(--text-color);
	background-color: var(--background-color);
}

html {
	overflow-y: scroll;
}

body {
	max-width: 65em;
}

/* https://www.a11yproject.com/posts/how-to-hide-content/ */
.visually-hidden {
	clip: rect(0 0 0 0);
	clip-path: inset(50%);
	height: 1px;
	overflow: hidden;
	position: absolute;
	white-space: nowrap;
	width: 1px;
}

p:last-child {
	margin-bottom: 0;
}

p {
	line-height: 1.5;
}

li {
	line-height: 1.5;
}

a[href] {
	color: var(--text-color-link);
}

a[href]:visited {
	color: var(--text-color-link-visited);
}

a[href]:hover,
a[href]:active {
	color: var(--text-color-link-active);
}

main,
footer {
	padding: 1rem;
}

main :first-child {
	margin-top: 0;
}

header {
	border-bottom: 1px dashed var(--color-gray-20);
}

header:after {
	content: "";
	display: table;
	clear: both;
}

.links-nextprev {
	display: flex;
	justify-content: space-between;
	gap: .5em 1em;
	list-style: "";
	border-top: 1px dashed var(--color-gray-20);
	padding: 1em 0;
}

.links-nextprev>* {
	flex-grow: 1;
}

.links-nextprev-next {
	text-align: right;
}

table {
	margin: 1em 0;
}

table td,
table th {
	padding-right: 1em;
}

pre,
code {
	font-family: var(--font-family-monospace);
}

pre:not([class*="language-"]) {
	margin: .5em 0;
	line-height: 1.375;
	/* 22px /16 */
	-moz-tab-size: var(--syntax-tab-size);
	-o-tab-size: var(--syntax-tab-size);
	tab-size: var(--syntax-tab-size);
	-webkit-hyphens: none;
	-ms-hyphens: none;
	hyphens: none;
	direction: ltr;
	text-align: left;
	white-space: pre;
	word-spacing: normal;
	word-break: normal;
	overflow-x: auto;
}

code {
	word-break: break-all;
}

/* Header */
header {
	display: flex;
	gap: 1em .5em;
	flex-wrap: wrap;
	align-items: center;
	padding: 1em;
}

.home-link {
	font-size: 1.2em;
	/* 16px /16 */
	font-weight: 700;
	margin-right: 2em;
}

.home-link:link:not(:hover) {
	text-decoration: none;
}

/* Nav */
.nav {
	display: flex;
	padding: 0;
	margin: 0;
	list-style: none;
}

.nav-item {
	display: inline-block;
	margin-right: 1em;
}

.nav-item a[href]:not(:hover) {
	text-decoration: none;
}

.nav a[href][aria-current="page"] {
	text-decoration: underline;
}

/* Posts list */
.postlist {
	list-style: none;
	padding: 0;
	padding-left: 1.5rem;
}

.postlist-item {
	display: flex;
	flex-wrap: wrap;
	align-items: baseline;
	counter-increment: start-from -1;
	margin-bottom: 1em;
}

.postlist-item:before {
	display: inline-block;
	pointer-events: none;
	content: "" counter(start-from, decimal-leading-zero) ". ";
	line-height: 100%;
	text-align: right;
	margin-left: -1.5rem;
}

.postlist-date,
.postlist-item:before {
	font-size: 0.8125em;
	/* 13px /16 */
	color: var(--color-gray-90);
}

.postlist-date {
	word-spacing: -0.5px;
}

.postlist-link {
	font-size: 1.1875em;
	/* 19px /16 */
	font-weight: 700;
	flex-basis: calc(100% - 1.5rem);
	padding-left: .25em;
	padding-right: .5em;
	text-underline-position: from-font;
	text-underline-offset: 0;
	text-decoration-thickness: 1px;
}

.postlist-item-active .postlist-link {
	font-weight: bold;
}

/* Tags */
.post-tag {
	display: inline-flex;
	align-items: center;
	justify-content: center;
	text-transform: capitalize;
	font-style: italic;
}

.postlist-item>.post-tag {
	align-self: center;
}

/* Tags list */
.post-metadata {
	display: inline-flex;
	flex-wrap: wrap;
	gap: .5em;
	list-style: none;
	padding: 0;
	margin: 0;
}

.post-metadata time {
	margin-right: 1em;
}

footer {
	text-align: center;
	padding: 20px 0;
}

.social-links {
	margin-top: 5px;
}

.social-links a {
	margin: 0 3px;
	text-decoration: none;
	color: #333;
}

.social-links a:hover {
	color: #cca4f4;
	/* Customize this color as needed */
}

.social-links i {
	font-size: 1.5em;
	/* Adjust size as needed */
}

.site-logo {
	max-width: 100px;
	/* Adjust the size as needed */
	height: auto;
	/* Maintain aspect ratio */
	display: block;
	margin: 0 auto;
	/* Center the logo */
}</style>
            </head><body><a href="#skip" class="visually-hidden">Skip to main content</a>
            <header>
                <a href="/" class="home-link">
                    <picture><source type="image/avif" srcset="/img/t_xVYiIA5X-512.avif 512w"><source type="image/webp" srcset="/img/t_xVYiIA5X-512.webp 512w"><img loading="lazy" decoding="async" src="/img/t_xVYiIA5X-512.png" alt="Yonatan Lourie logo" class="site-logo" width="512" height="512"></picture>
                </a>
            
            <a href="/" class="home-link">Yonatan Lourie</a>
            <nav>
                <h2 class="visually-hidden" id="top-level-navigation-menu">Top level navigation menu</h2>
                <ul class="nav">
                        <li class="nav-item">
                            <a href="/">Home</a>
                        </li>
                        <li class="nav-item">
                            <a href="/blog/">Blog</a>
                        </li>
                        <li class="nav-item">
                            <a href="/about/">About</a>
                        </li>
                        <li class="nav-item">
                            <a href="/Links/">Links</a>
                        </li>
                        <li class="nav-item">
                            <a href="/projects/">Projects</a>
                        </li>
                        <li class="nav-item">
                            <a href="/feed/feed.xml">Feed</a>
                        </li>
                </ul>
            </nav>
        </header></body>
    
</html><main id="skip">
<heading-anchors>
    
<h1 id="how-to-use-the-qumran-scrolls-for-nlp-tasks-using-text-fabric">How to use the Qumran scrolls for NLP tasks using text-fabric</h1>

<ul class="post-metadata">
	<li><time datetime="2024-10-30">30 October 2024</time></li>
</ul>

<p>When I first started my thesis, I inherited the Dead Sea Scrolls project from another student in my lab. He provided a large file that looked something like this:<br>
&lt;img src=&quot;abeg_origin.png&quot; alt=&quot;abeg_origin&quot; width=&quot;10&quot;/&gt;</p>
<p>I also inherited a complex spaghetti code that parsed this data into readable Hebrew text. These files (from the image above),  were created by <a href="https://en.wikipedia.org/wiki/Martin_Abegg">Martin Abegg</a> and contain the raw text of the Dead Sea Scrolls, with morphological data on each word.</p>
<p>A few weeks later, I discovered the <a href="https://github.com/annotation/text-fabric">text-fabric</a> package, a toolkit for analyzing large, structured text datasets, including ancient manuscripts, biblical texts, and other linguistically complex corpora. Popular among researchers in linguistics, biblical studies, and digital humanities.</p>
<p>This package actually parsing those files that looks like gibberish from Abegg, but with easy to use API.</p>
<p>For my purposes, I needed the entire corpus as plain text, along with some morphological features of each word. Here’s a quick guide on how to set it up:</p>
<p><strong>Disclaimer</strong>
The original documentation for this package is pretty good, but i felt that the learning curve was too steep for what I needed. This post is very simple, and it will be good if you need to do something similar to mine.</p>
<h2 id="installation">Installation</h2>
<p>Follow the instructions in <a href="https://annotation.github.io/text-fabric/tf/about/install.html">here</a>.
If you having problems, you can try to install it with: <code>pip instal 'text-fabric[github]'</code>.</p>
<h3 id="installation-and-setup">Installation and Setup</h3>
<p>(For more comprehensive guide check the <a href="https://annotation.github.io/text-fabric/tf/index.html">documentation</a>)
To get started, you’ll need to install <code>text-fabric</code> and load a dataset.
Here’s an example using the ETCBC Hebrew Bible dataset:</p>
<pre class="language-python" tabindex="0"><code class="language-python"><span class="token comment"># Import Text-Fabric and load a dataset</span>
<span class="token keyword">from</span> tf<span class="token punctuation">.</span>app <span class="token keyword">import</span> use

<span class="token comment"># Load the Hebrew Bible (ETCBC dataset)</span>
A <span class="token operator">=</span> use<span class="token punctuation">(</span><span class="token string">'etcbc/bhsa'</span><span class="token punctuation">,</span> hoist<span class="token operator">=</span><span class="token builtin">globals</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>
<p><strong>Some basic operations:</strong></p>
<ul>
<li>Get the Text Structure: You can load text elements by type (book, chapter, verse) and navigate through them.</li>
</ul>
<pre class="language-python" tabindex="0"><code class="language-python"><span class="token comment"># Get all books</span>
<span class="token keyword">for</span> book <span class="token keyword">in</span> F<span class="token punctuation">.</span>otype<span class="token punctuation">.</span>s<span class="token punctuation">(</span><span class="token string">'book'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>F<span class="token punctuation">.</span>book<span class="token punctuation">.</span>v<span class="token punctuation">(</span>book<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># Prints book names</span></code></pre>
<ul>
<li>Accessing Specific Text Data: Let’s retrieve a verse in Genesis.</li>
</ul>
<pre class="language-python" tabindex="0"><code class="language-python"><span class="token comment"># Get Genesis 1:1</span>
verse_node <span class="token operator">=</span> T<span class="token punctuation">.</span>nodeFromSection<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">'Genesis'</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>T<span class="token punctuation">.</span>text<span class="token punctuation">(</span>verse_node<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># Outputs the text of Genesis 1:1</span>
</code></pre>
<ul>
<li>Accessing Metadata: You can retrieve metadata for specific elements like morphology or part of speech.</li>
</ul>
<pre class="language-python" tabindex="0"><code class="language-python"><span class="token comment"># Get morphological and part of speech info for a specific word in Genesis 1:1</span>
word_node <span class="token operator">=</span> L<span class="token punctuation">.</span>d<span class="token punctuation">(</span>verse_node<span class="token punctuation">,</span> otype<span class="token operator">=</span><span class="token string">'word'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>  <span class="token comment"># First word in Genesis 1:1</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>F<span class="token punctuation">.</span>lex<span class="token punctuation">.</span>v<span class="token punctuation">(</span>word_node<span class="token punctuation">)</span><span class="token punctuation">,</span> F<span class="token punctuation">.</span>sp<span class="token punctuation">.</span>v<span class="token punctuation">(</span>word_node<span class="token punctuation">)</span><span class="token punctuation">,</span> F<span class="token punctuation">.</span>g_cons<span class="token punctuation">.</span>v<span class="token punctuation">(</span>word_node<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<h2 id="implementation">Implementation</h2>
<p>For my case, i wanted to use the DSS dataset. the implementation is pretty straight forward: run over each scroll, store each word as a dict (each word have few attributes). That means we eventually end up with a dict of dict of dicts</p>
<pre class="language-cmd" tabindex="0"><code class="language-cmd">{scroll1:[{text:ושמע, lex:שמע, ...}, {text:ה׳, lex:ה, ...}], 
scroll2:[{text:רצה, lex:רצה, ...}, {text:משה, lex:משה, ...}]}</code></pre>
<p>The value for each scroll is simply a list of the words of this scroll (with a lot features expect from the raw text).</p>
<h3 id="simple-run">Simple run</h3>
<p>In here, we will iterate over the whole corpus (scroll by scroll), and gather the words for each scroll (with the corresponding location in the scroll).</p>
<pre class="language-python" tabindex="0"><code class="language-python"><span class="token keyword">from</span> collections <span class="token keyword">import</span> defaultdict
<span class="token keyword">from</span> tf<span class="token punctuation">.</span>app <span class="token keyword">import</span> use
<span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm

<span class="token keyword">def</span> <span class="token function">get_scroll_and_chapter_info</span><span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Get scroll and chapter information for a given word node."""</span>
    scroll_and_chapter <span class="token operator">=</span> A<span class="token punctuation">.</span>sectionStrFromNode<span class="token punctuation">(</span>word<span class="token punctuation">)</span>
    scroll<span class="token punctuation">,</span> chapter_info <span class="token operator">=</span> scroll_and_chapter<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> scroll_and_chapter<span class="token punctuation">,</span> scroll


<span class="token keyword">def</span> <span class="token function">process_word</span><span class="token punctuation">(</span>scroll_node<span class="token punctuation">,</span> word_line_num<span class="token punctuation">,</span> sub_word_num<span class="token punctuation">)</span><span class="token punctuation">:</span>
    single_scroll_data <span class="token operator">=</span> defaultdict<span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> word <span class="token keyword">in</span> L<span class="token punctuation">.</span>d<span class="token punctuation">(</span>scroll_node<span class="token punctuation">,</span> otype<span class="token operator">=</span><span class="token string">"word"</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment">#running over all of the words of this scroll</span>
        <span class="token punctuation">(</span>
            scroll_and_chapter<span class="token punctuation">,</span>
            scroll
        <span class="token punctuation">)</span> <span class="token operator">=</span> get_scroll_and_chapter_info<span class="token punctuation">(</span>word<span class="token punctuation">)</span>
        transcript <span class="token operator">=</span> T<span class="token punctuation">.</span>text<span class="token punctuation">(</span>word<span class="token punctuation">)</span> <span class="token comment">#get raw text</span>
        word_entry <span class="token operator">=</span> <span class="token punctuation">{</span>
            <span class="token string">"book_and_chapter"</span><span class="token punctuation">:</span> scroll_and_chapter<span class="token punctuation">,</span>
            <span class="token string">"scroll_name"</span><span class="token punctuation">:</span> scroll<span class="token punctuation">,</span>
            <span class="token string">"transcript"</span><span class="token punctuation">:</span> transcript<span class="token punctuation">,</span>

        <span class="token punctuation">}</span>
        single_scroll_data<span class="token punctuation">[</span>scroll<span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>word_entry<span class="token punctuation">)</span>
    <span class="token keyword">return</span> single_scroll_data


A <span class="token operator">=</span> use<span class="token punctuation">(</span><span class="token string">"ETCBC/dss"</span><span class="token punctuation">,</span> hoist<span class="token operator">=</span><span class="token builtin">globals</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#here we will load the DSS (dead sea scrolls) data</span>

all_scrolls <span class="token operator">=</span> defaultdict<span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> scroll_node <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span>F<span class="token punctuation">.</span>otype<span class="token punctuation">.</span>s<span class="token punctuation">(</span><span class="token string">"scroll"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment">#running over all scrolls available</span>
    word_line_num <span class="token operator">=</span> <span class="token number">1</span> <span class="token comment">#first line</span>
    sub_word_num <span class="token operator">=</span> <span class="token number">1</span> <span class="token comment">#first place in the line</span>
    scroll_data <span class="token operator">=</span> process_word<span class="token punctuation">(</span>scroll_node<span class="token punctuation">,</span> word_line_num<span class="token punctuation">,</span> sub_word_num<span class="token punctuation">)</span>
    all_scrolls<span class="token punctuation">.</span>update<span class="token punctuation">(</span>scroll_data<span class="token punctuation">)</span>
</code></pre>
<p>But in case you want to get much rich data you can use something more complex like:</p>
<pre class="language-python" tabindex="0"><code class="language-python"><span class="token keyword">def</span> <span class="token function">get_morphological_features</span><span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Extract morphological features for a given word node."""</span>
    <span class="token keyword">return</span> <span class="token punctuation">{</span>
        <span class="token string">"sp"</span><span class="token punctuation">:</span> F<span class="token punctuation">.</span>sp<span class="token punctuation">.</span>v<span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token string">"cl"</span><span class="token punctuation">:</span> F<span class="token punctuation">.</span>cl<span class="token punctuation">.</span>v<span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token string">"ps"</span><span class="token punctuation">:</span> F<span class="token punctuation">.</span>ps<span class="token punctuation">.</span>v<span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token string">"gn"</span><span class="token punctuation">:</span> F<span class="token punctuation">.</span>gn<span class="token punctuation">.</span>v<span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token string">"nu"</span><span class="token punctuation">:</span> F<span class="token punctuation">.</span>nu<span class="token punctuation">.</span>v<span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token string">"st"</span><span class="token punctuation">:</span> F<span class="token punctuation">.</span>st<span class="token punctuation">.</span>v<span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token string">"vs"</span><span class="token punctuation">:</span> F<span class="token punctuation">.</span>vs<span class="token punctuation">.</span>v<span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token string">"vt"</span><span class="token punctuation">:</span> F<span class="token punctuation">.</span>vt<span class="token punctuation">.</span>v<span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token string">"md"</span><span class="token punctuation">:</span> F<span class="token punctuation">.</span>md<span class="token punctuation">.</span>v<span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">}</span>


<span class="token keyword">def</span> <span class="token function">get_scroll_and_chapter_info</span><span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Get scroll and chapter information for a given word node."""</span>
    scroll_and_chapter <span class="token operator">=</span> A<span class="token punctuation">.</span>sectionStrFromNode<span class="token punctuation">(</span>word<span class="token punctuation">)</span>
    scroll<span class="token punctuation">,</span> chapter_info <span class="token operator">=</span> scroll_and_chapter<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span>
    frag_label<span class="token punctuation">,</span> frag_line_num <span class="token operator">=</span> chapter_info<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">":"</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> scroll_and_chapter<span class="token punctuation">,</span> scroll<span class="token punctuation">,</span> frag_label<span class="token punctuation">,</span> frag_line_num


<span class="token keyword">def</span> <span class="token function">process_word</span><span class="token punctuation">(</span>scroll_node<span class="token punctuation">,</span> word_line_num<span class="token punctuation">,</span> sub_word_num<span class="token punctuation">)</span><span class="token punctuation">:</span>
    single_scroll_data <span class="token operator">=</span> defaultdict<span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> word <span class="token keyword">in</span> L<span class="token punctuation">.</span>d<span class="token punctuation">(</span>scroll_node<span class="token punctuation">,</span> otype<span class="token operator">=</span><span class="token string">"word"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token punctuation">(</span>
            scroll_and_chapter<span class="token punctuation">,</span>
            scroll<span class="token punctuation">,</span>
            frag_label<span class="token punctuation">,</span>
            frag_line_num<span class="token punctuation">,</span>
        <span class="token punctuation">)</span> <span class="token operator">=</span> get_scroll_and_chapter_info<span class="token punctuation">(</span>word<span class="token punctuation">)</span>
        transcript <span class="token operator">=</span> T<span class="token punctuation">.</span>text<span class="token punctuation">(</span>word<span class="token punctuation">)</span>
        lexeme <span class="token operator">=</span> F<span class="token punctuation">.</span>glex<span class="token punctuation">.</span>v<span class="token punctuation">(</span>word<span class="token punctuation">)</span>
        morphological_features <span class="token operator">=</span> get_morphological_features<span class="token punctuation">(</span>word<span class="token punctuation">)</span>
        lang <span class="token operator">=</span> F<span class="token punctuation">.</span>lang<span class="token punctuation">.</span>v<span class="token punctuation">(</span>word<span class="token punctuation">)</span>
        srcLn <span class="token operator">=</span> F<span class="token punctuation">.</span>srcLn<span class="token punctuation">.</span>v<span class="token punctuation">(</span>word<span class="token punctuation">)</span>
        word_type <span class="token operator">=</span> F<span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">.</span>v<span class="token punctuation">(</span>word<span class="token punctuation">)</span>
        after <span class="token operator">=</span> F<span class="token punctuation">.</span>after<span class="token punctuation">.</span>v<span class="token punctuation">(</span>word<span class="token punctuation">)</span>

        word_entry <span class="token operator">=</span> <span class="token punctuation">{</span>
            <span class="token string">"frag_label"</span><span class="token punctuation">:</span> frag_label<span class="token punctuation">,</span>
            <span class="token string">"frag_line_num"</span><span class="token punctuation">:</span> frag_line_num<span class="token punctuation">,</span>
            <span class="token string">"word_line_num"</span><span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">(</span>word_line_num<span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token string">"sub_word_num"</span><span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">(</span>sub_word_num<span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token string">"book_and_chapter"</span><span class="token punctuation">:</span> scroll_and_chapter<span class="token punctuation">,</span>
            <span class="token string">"scroll_name"</span><span class="token punctuation">:</span> scroll<span class="token punctuation">,</span>
            <span class="token string">"transcript"</span><span class="token punctuation">:</span> transcript<span class="token punctuation">,</span>
            <span class="token string">"lex"</span><span class="token punctuation">:</span> lexeme<span class="token punctuation">,</span>
            <span class="token string">"parsed_morph"</span><span class="token punctuation">:</span> morphological_features<span class="token punctuation">,</span>
            <span class="token string">"lang"</span><span class="token punctuation">:</span> lang<span class="token punctuation">,</span>
            <span class="token string">"srcLn"</span><span class="token punctuation">:</span> srcLn<span class="token punctuation">,</span>
            <span class="token string">"type_of"</span><span class="token punctuation">:</span> word_type<span class="token punctuation">,</span>
            <span class="token string">"after"</span><span class="token punctuation">:</span> after<span class="token punctuation">,</span>
        <span class="token punctuation">}</span>
        

        <span class="token keyword">if</span> <span class="token punctuation">(</span>
            <span class="token keyword">not</span> after
        <span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># If there is no space after the word, it means it's a conjunction like ו or ב.</span>
            sub_word_num <span class="token operator">+=</span> <span class="token number">1</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            sub_word_num <span class="token operator">=</span> <span class="token number">1</span>
            word_line_num <span class="token operator">+=</span> <span class="token number">1</span>

        single_scroll_data<span class="token punctuation">[</span>scroll<span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>word_entry<span class="token punctuation">)</span>
    <span class="token keyword">return</span> single_scroll_data
</code></pre>
<p>That's it, from here you can do whatever you want with the data.
For more context and much ordered pipeline you can take a peek in here: <a href="https://github.com/yonatanlou/QumranNLP/blob/main/src/ETL/main_ETL.py">main_ETL.py</a>.</p>

<ul class="links-nextprev"><li class="links-nextprev-prev">← Previous<br> <a href="/blog/firstpost/">Moving from Jekyll to Eleventy.</a></li><li class="links-nextprev-next">Next →<br><a href="/blog/jaccard-index-unsupervised/Jaccard_index_for_unsupervised_clustering/">Jaccard index for unsupervised clustering</a></li>
</ul>

</heading-anchors></main><footer>
<div class="social-links">
    <a href="https://www.goodreads.com/user/show/103722180-yonatan-lourie" target="_blank" title="Goodreads">
        <i class="fab fa-goodreads"></i>
    </a>
    <a href="https://www.imdb.com/user/ur88119677/ratings/" target="_blank" title="IMDb">
        <i class="fab fa-imdb"></i>
    </a>
    <a href="https://open.spotify.com/user/224udkuetwxsiqba7n4tums6q?si=_RD2kBO8QlSUYLfjBLjBEQ&nd=1" target="_blank" title="Spotify">
        <i class="fab fa-spotify"></i>
    </a>
    <a href="https://x.com/yonatanlou" target="_blank" title="Twitter">
        <i class="fab fa-twitter"></i>
    </a>
    <a href="https://www.linkedin.com/in/yonatanlourie/" target="_blank" title="LinkedIn">
        <i class="fab fa-linkedin"></i>
    </a>
    <a href="https://github.com/yonatanlou" target="_blank" title="GitHub">
        <i class="fab fa-github"></i>
    </a>
    <a href="mailto:yonatanlou@gmail.com" target="_blank" title="Email">
        <i class="fa-solid fa-envelope"></i>
    </a>
</div></footer><!-- This page `/blog/data-pipeline-for-qumran-scrolls/data-pipeline-for-the-qumran-scrolls-using-text-fabric/` was built on 2025-06-21T07:32:52.598Z --><script type="module" src="/dist/rJ3_G-2ArF.js"></script>